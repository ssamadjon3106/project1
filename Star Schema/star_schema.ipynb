{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62227d36",
   "metadata": {},
   "source": [
    "# Star Schema Design and Implementation in Jupyter Notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ca3fc396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Creating dimension tables...\n",
      "Creating fact table...\n",
      "Creating bridge table...\n",
      "Saving to Excel...\n",
      "\n",
      "Star schema successfully created with:\n",
      "- 253 users in dim_user\n",
      "- 15 communications in fact_communication\n",
      "- 296 relationships in bridge_comm_user\n",
      "Output saved to final_output_with_names.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import uuid\n",
    "import re\n",
    "from datetime import datetime\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.styles import Font, Alignment, Border, Side\n",
    "\n",
    "def extract_json_data(row):\n",
    "    \"\"\"Extract JSON data from raw_content with error handling\"\"\"\n",
    "    try:\n",
    "        content = row.get('raw_content', '{}')\n",
    "        if pd.isna(content) or not content:\n",
    "            return {}\n",
    "        return json.loads(content)\n",
    "    except json.JSONDecodeError:\n",
    "        try:\n",
    "            # Try to fix malformed JSON\n",
    "            fixed = content.replace(\"'\", '\"').replace('None', 'null')\n",
    "            return json.loads(fixed)\n",
    "        except:\n",
    "            return {}\n",
    "    except Exception:\n",
    "        return {}\n",
    "\n",
    "\n",
    "def load_and_prepare_data(file_path):\n",
    "    \"\"\"Load and prepare the raw data\"\"\"\n",
    "    raw_df = pd.read_excel(file_path, sheet_name='Sheet1')\n",
    "    \n",
    "    # Ensure required columns exist\n",
    "    required_cols = ['id', 'comm_type', 'raw_content', 'subject']\n",
    "    for col in required_cols:\n",
    "        if col not in raw_df.columns:\n",
    "            raw_df[col] = None\n",
    "    \n",
    "    # Extract JSON data\n",
    "    json_data = raw_df.apply(extract_json_data, axis=1)\n",
    "    json_df = pd.json_normalize(json_data)\n",
    "    \n",
    "    # Combine with raw data, avoiding duplicate columns\n",
    "    for col in json_df.columns:\n",
    "        if col not in raw_df.columns:\n",
    "            raw_df[col] = json_df[col]\n",
    "    \n",
    "    return raw_df\n",
    "\n",
    "def create_dimension_tables(raw_df):\n",
    "    \"\"\"Create all dimension tables with enhanced name extraction\"\"\"\n",
    "    # dim_comm_type\n",
    "    comm_types = raw_df['comm_type'].dropna().unique()\n",
    "    dim_comm_type = pd.DataFrame({\n",
    "        'comm_type': comm_types,\n",
    "        'comm_type_id': range(1, len(comm_types) + 1)\n",
    "    })\n",
    "    \n",
    "    # dim_subject\n",
    "    subjects = raw_df['subject'].dropna().unique()\n",
    "    dim_subject = pd.DataFrame({\n",
    "        'subject': subjects,\n",
    "        'subject_id': range(1, len(subjects) + 1)\n",
    "    })\n",
    "    \n",
    "    # dim_user - collect all unique users from various fields\n",
    "    user_records = []\n",
    "    seen_emails = set()\n",
    "    \n",
    "    speaker_data = {}\n",
    "    for _, row in raw_df.iterrows():\n",
    "        content = extract_json_data(row)\n",
    "        if not content:\n",
    "            continue\n",
    "        \n",
    "        for speaker in content.get('speakers', []):\n",
    "            if isinstance(speaker, dict):\n",
    "                name = speaker.get('name')\n",
    "                email = speaker.get('email', '').lower().strip()\n",
    "                if email:  # Only store if we have an email\n",
    "                    speaker_data[email] = {\n",
    "                        'name': name,\n",
    "                        'location': speaker.get('location'),\n",
    "                        'displayName': speaker.get('displayName'),\n",
    "                        'phoneNumber': speaker.get('phoneNumber')\n",
    "                    }\n",
    "    \n",
    "    # Second pass: Process all data sources\n",
    "    for _, row in raw_df.iterrows():\n",
    "        content = extract_json_data(row)\n",
    "        if not content:\n",
    "            continue\n",
    "        \n",
    "        # Process all potential email sources\n",
    "        email_sources = []\n",
    "        \n",
    "        # Speakers\n",
    "        email_sources.extend(\n",
    "            (speaker.get('email', '').lower().strip(), 'speaker') \n",
    "            for speaker in content.get('speakers', []) \n",
    "            if isinstance(speaker, dict)\n",
    "        )\n",
    "        \n",
    "        # Participants\n",
    "        for participant in content.get('participants', []):\n",
    "            if isinstance(participant, dict):\n",
    "                email = participant.get('email', '').lower().strip()\n",
    "                if email:\n",
    "                    email_sources.append((email, 'participant'))\n",
    "            elif isinstance(participant, str):\n",
    "                email = participant.lower().strip()\n",
    "                if email:\n",
    "                    email_sources.append((email, 'participant'))\n",
    "        \n",
    "        # Meeting attendees\n",
    "        email_sources.extend(\n",
    "            (attendee.get('email', '').lower().strip(), 'attendee') \n",
    "            for attendee in content.get('meeting_attendees', []) \n",
    "            if isinstance(attendee, dict)\n",
    "        )\n",
    "        \n",
    "        # Organizer\n",
    "        organizer_email = content.get('organizer_email', '').lower().strip()\n",
    "        if organizer_email:\n",
    "            email_sources.append((organizer_email, 'organizer'))\n",
    "        \n",
    "        # Create user records for unique emails\n",
    "        for email, source in email_sources:\n",
    "            if email and email not in seen_emails:\n",
    "                seen_emails.add(email)\n",
    "                \n",
    "                \n",
    "                user_records.append({\n",
    "                    'name': name,\n",
    "                    'email': email,\n",
    "                    'location': speaker_data.get(email, {}).get('location'),\n",
    "                    'displayName': speaker_data.get(email, {}).get('displayName'),\n",
    "                    'phoneNumber': speaker_data.get(email, {}).get('phoneNumber')\n",
    "                })\n",
    "    \n",
    "    # Create final dim_user table\n",
    "    dim_user_columns = ['user_id', 'name', 'email', 'location', 'displayName', 'phoneNumber']\n",
    "    if user_records:\n",
    "        dim_user = pd.DataFrame(user_records)\n",
    "        dim_user['user_id'] = [str(uuid.uuid4()) for _ in range(len(dim_user))]\n",
    "    else:\n",
    "        dim_user = pd.DataFrame(columns=dim_user_columns)\n",
    "    \n",
    "    # Ensure all columns exist\n",
    "    for col in dim_user_columns[1:]:\n",
    "        if col not in dim_user.columns:\n",
    "            dim_user[col] = None\n",
    "    \n",
    "    # Other dimensions\n",
    "    dim_calendar = pd.DataFrame({\n",
    "        'raw_calendar_id': raw_df['calendar_id'].dropna().unique(),\n",
    "        'calendar_id': range(1, len(raw_df['calendar_id'].dropna().unique()) + 1)\n",
    "    }) if 'calendar_id' in raw_df.columns else pd.DataFrame(columns=['raw_calendar_id', 'calendar_id'])\n",
    "    \n",
    "    dim_audio = pd.DataFrame({\n",
    "        'raw_audio_url': raw_df['audio_url'].dropna().unique(),\n",
    "        'audio_id': range(1, len(raw_df['audio_url'].dropna().unique()) + 1)\n",
    "    }) if 'audio_url' in raw_df.columns else pd.DataFrame(columns=['raw_audio_url', 'audio_id'])\n",
    "    \n",
    "    dim_video = pd.DataFrame(columns=['raw_video_url', 'video_id'])\n",
    "    \n",
    "    dim_transcript = pd.DataFrame({\n",
    "        'raw_transcript_url': raw_df['transcript_url'].dropna().unique(),\n",
    "        'transcript_id': range(1, len(raw_df['transcript_url'].dropna().unique()) + 1)\n",
    "    }) if 'transcript_url' in raw_df.columns else pd.DataFrame(columns=['raw_transcript_url', 'transcript_id'])\n",
    "    \n",
    "    return {\n",
    "        'dim_comm_type': dim_comm_type,\n",
    "        'dim_subject': dim_subject,\n",
    "        'dim_user': dim_user,\n",
    "        'dim_calendar': dim_calendar,\n",
    "        'dim_audio': dim_audio,\n",
    "        'dim_video': dim_video,\n",
    "        'dim_transcript': dim_transcript\n",
    "    }\n",
    "\n",
    "def create_fact_table(raw_df, dimensions):\n",
    "    \"\"\"Create the fact communication table\"\"\"\n",
    "    # Initialize with required columns\n",
    "    fact_columns = [\n",
    "        'comm_id', 'raw_id', 'source_id', 'comm_type_id', 'subject_id',\n",
    "        'calendar_id', 'audio_id', 'video_id', 'transcript_id', 'datetime_id',\n",
    "        'ingested_at', 'processed_at', 'is_processed', 'raw_title', 'raw_duration'\n",
    "    ]\n",
    "    \n",
    "    if raw_df.empty:\n",
    "        return pd.DataFrame(columns=fact_columns)\n",
    "    \n",
    "    # Create base dataframe with only the columns we need\n",
    "    base_cols = ['id', 'comm_type', 'subject', 'source_id', 'ingested_at', 'processed_at', 'is_processed']\n",
    "    fact_df = raw_df[[col for col in base_cols if col in raw_df.columns]].copy()\n",
    "    \n",
    "    # Rename columns\n",
    "    fact_df = fact_df.rename(columns={\n",
    "        'id': 'comm_id',\n",
    "        'comm_type': 'comm_type',\n",
    "        'subject': 'subject',\n",
    "        'source_id': 'source_id'\n",
    "    })\n",
    "    \n",
    "    # Add fields from JSON data\n",
    "    json_fields = {\n",
    "        'raw_id': 'id',\n",
    "        'raw_title': 'title',\n",
    "        'raw_duration': 'duration',\n",
    "        'datetime_id': 'dateString',\n",
    "        'raw_calendar_id': 'calendar_id',\n",
    "        'audio_url': 'audio_url',\n",
    "        'transcript_url': 'transcript_url'\n",
    "    }\n",
    "    \n",
    "    for new_col, old_col in json_fields.items():\n",
    "        if old_col in raw_df.columns:\n",
    "            if new_col == 'datetime_id':\n",
    "                fact_df[new_col] = pd.to_datetime(raw_df[old_col], errors='coerce')\n",
    "            else:\n",
    "                fact_df[new_col] = raw_df[old_col].copy()\n",
    "        else:\n",
    "            fact_df[new_col] = None\n",
    "    \n",
    "    # Merge with dimension tables carefully\n",
    "    for dim_name, dim_col, fact_col in [\n",
    "        ('dim_comm_type', 'comm_type', 'comm_type'),\n",
    "        ('dim_subject', 'subject', 'subject'),\n",
    "        ('dim_calendar', 'raw_calendar_id', 'raw_calendar_id'),\n",
    "        ('dim_audio', 'raw_audio_url', 'audio_url'),\n",
    "        ('dim_transcript', 'raw_transcript_url', 'transcript_url')\n",
    "    ]:\n",
    "        if dim_name in dimensions and not dimensions[dim_name].empty and fact_col in fact_df.columns:\n",
    "            # Drop duplicate columns before merge\n",
    "            dim_df = dimensions[dim_name].drop(columns=[c for c in dimensions[dim_name].columns if c in fact_df.columns and c != dim_col])\n",
    "            fact_df = fact_df.merge(\n",
    "                dim_df,\n",
    "                left_on=fact_col,\n",
    "                right_on=dim_col,\n",
    "                how='left'\n",
    "            )\n",
    "    \n",
    "    # Add video_id (empty)\n",
    "    fact_df['video_id'] = None\n",
    "    \n",
    "    # Ensure we have all required columns\n",
    "    for col in fact_columns:\n",
    "        if col not in fact_df.columns:\n",
    "            fact_df[col] = None\n",
    "    \n",
    "    # Select final columns\n",
    "    return fact_df[fact_columns]\n",
    "\n",
    "def create_bridge_table(raw_df, dim_user):\n",
    "    \"\"\"Create bridge table between communications and users\"\"\"\n",
    "    bridge_columns = ['comm_id', 'user_id', 'isSpeaker', 'isParticipant', 'isAttendee', 'isOrganiser']\n",
    "    \n",
    "    if raw_df.empty or dim_user.empty:\n",
    "        return pd.DataFrame(columns=bridge_columns)\n",
    "    \n",
    "    bridge_records = []\n",
    "    \n",
    "    for _, row in raw_df.iterrows():\n",
    "        comm_id = row['id']\n",
    "        content = extract_json_data(row)\n",
    "        if not content:\n",
    "            continue\n",
    "        \n",
    "        # Process speakers\n",
    "        for speaker in content.get('speakers', []):\n",
    "            email = speaker.get('email', '').lower().strip() if isinstance(speaker, dict) else ''\n",
    "            if email:\n",
    "                bridge_records.append({\n",
    "                    'comm_id': comm_id,\n",
    "                    'email': email,\n",
    "                    'isSpeaker': True,\n",
    "                    'isParticipant': False,\n",
    "                    'isAttendee': False,\n",
    "                    'isOrganiser': False\n",
    "                })\n",
    "        \n",
    "        # Process participants\n",
    "        for participant in content.get('participants', []):\n",
    "            if isinstance(participant, dict):\n",
    "                email = participant.get('email', '').lower().strip()\n",
    "            elif isinstance(participant, str):\n",
    "                email = participant.lower().strip()\n",
    "            else:\n",
    "                email = ''\n",
    "            \n",
    "            if email:\n",
    "                bridge_records.append({\n",
    "                    'comm_id': comm_id,\n",
    "                    'email': email,\n",
    "                    'isSpeaker': False,\n",
    "                    'isParticipant': True,\n",
    "                    'isAttendee': False,\n",
    "                    'isOrganiser': False\n",
    "                })\n",
    "        \n",
    "        # Process meeting attendees\n",
    "        for attendee in content.get('meeting_attendees', []):\n",
    "            if isinstance(attendee, dict):\n",
    "                email = attendee.get('email', '').lower().strip()\n",
    "                if email:\n",
    "                    bridge_records.append({\n",
    "                        'comm_id': comm_id,\n",
    "                        'email': email,\n",
    "                        'isSpeaker': False,\n",
    "                        'isParticipant': False,\n",
    "                        'isAttendee': True,\n",
    "                        'isOrganiser': False\n",
    "                    })\n",
    "        \n",
    "        # Process organizer\n",
    "        organizer_email = content.get('organizer_email', '').lower().strip()\n",
    "        if organizer_email:\n",
    "            bridge_records.append({\n",
    "                'comm_id': comm_id,\n",
    "                'email': organizer_email,\n",
    "                'isSpeaker': False,\n",
    "                'isParticipant': False,\n",
    "                'isAttendee': True,\n",
    "                'isOrganiser': True\n",
    "            })\n",
    "    \n",
    "    # Create bridge table\n",
    "    if not bridge_records:\n",
    "        return pd.DataFrame(columns=bridge_columns)\n",
    "    \n",
    "    bridge_df = pd.DataFrame(bridge_records)\n",
    "    \n",
    "    # Merge with dim_user to get user_id\n",
    "    if not dim_user.empty and 'email' in dim_user.columns:\n",
    "        bridge_df = bridge_df.merge(\n",
    "            dim_user[['user_id', 'email']].drop_duplicates(),\n",
    "            on='email',\n",
    "            how='left'\n",
    "        )\n",
    "    else:\n",
    "        bridge_df['user_id'] = None\n",
    "    \n",
    "    # Select final columns\n",
    "    return bridge_df[bridge_columns].drop_duplicates()\n",
    "\n",
    "def save_to_excel(data, output_file):\n",
    "    \"\"\"Save all tables to Excel with formatting\"\"\"\n",
    "    with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "        for sheet_name, df in data.items():\n",
    "            # Skip empty DataFrames\n",
    "            if df.empty:\n",
    "                continue\n",
    "                \n",
    "            df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "            \n",
    "            # Apply formatting\n",
    "            worksheet = writer.sheets[sheet_name]\n",
    "            \n",
    "            # Set column widths\n",
    "            for column in worksheet.columns:\n",
    "                max_length = max(\n",
    "                    len(str(cell.value)) if cell.value else 0\n",
    "                    for cell in column\n",
    "                )\n",
    "                adjusted_width = (max_length + 2) * 1.2\n",
    "                worksheet.column_dimensions[column[0].column_letter].width = adjusted_width\n",
    "            \n",
    "            # Format header\n",
    "            for cell in worksheet[1]:\n",
    "                cell.font = Font(bold=True)\n",
    "                cell.alignment = Alignment(horizontal='center')\n",
    "                cell.border = Border(bottom=Side(border_style='thin', color='000000'))\n",
    "\n",
    "def main():\n",
    "    input_file = \"raw_data.xlsx\"\n",
    "    output_file = \"final_output_with_names.xlsx\"\n",
    "    \n",
    "    print(\"Loading data...\")\n",
    "    raw_df = load_and_prepare_data(input_file)\n",
    "    \n",
    "    print(\"Creating dimension tables...\")\n",
    "    dimensions = create_dimension_tables(raw_df)\n",
    "    \n",
    "    print(\"Creating fact table...\")\n",
    "    fact_table = create_fact_table(raw_df, dimensions)\n",
    "    \n",
    "    print(\"Creating bridge table...\")\n",
    "    bridge_table = create_bridge_table(raw_df, dimensions['dim_user'])\n",
    "    \n",
    "    # Combine all tables\n",
    "    all_tables = {\n",
    "        'dim_comm_type': dimensions['dim_comm_type'],\n",
    "        'dim_subject': dimensions['dim_subject'],\n",
    "        'dim_user': dimensions['dim_user'],\n",
    "        'dim_calendar': dimensions['dim_calendar'],\n",
    "        'dim_audio': dimensions['dim_audio'],\n",
    "        'dim_video': dimensions['dim_video'],\n",
    "        'dim_transcript': dimensions['dim_transcript'],\n",
    "        'fact_communication': fact_table,\n",
    "        'bridge_comm_user': bridge_table\n",
    "    }\n",
    "    \n",
    "    print(\"Saving to Excel...\")\n",
    "    save_to_excel(all_tables, output_file)\n",
    "    \n",
    "    print(\"\\nStar schema successfully created with:\")\n",
    "    print(f\"- {len(dimensions['dim_user'])} users in dim_user\")\n",
    "    print(f\"- {len(fact_table)} communications in fact_communication\")\n",
    "    print(f\"- {len(bridge_table)} relationships in bridge_comm_user\")\n",
    "    print(f\"Output saved to {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed5e6f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
